#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script ƒë·ªÉ crawl d·ªØ li·ªáu xe t·ª´ willhaben.at b·∫±ng headless browser
"""

import json
import re
import time
import sys
from pathlib import Path
from bs4 import BeautifulSoup

def crawl_with_requests():
    """
    Th·ª≠ crawl b·∫±ng requests tr∆∞·ªõc
    """
    print("üöÄ Th·ª≠ crawl b·∫±ng requests...")
    
    try:
        import requests
        from fake_useragent import UserAgent
        
        ua = UserAgent()
        headers = {
            'User-Agent': ua.random,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'de-DE,de;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        url = "https://www.willhaben.at/iad/gebrauchtwagen/auto/gebrauchtwagenboerse"
        
        response = requests.get(url, headers=headers, timeout=30)
        print(f"‚úÖ Status code: {response.status_code}")
        print(f"üìÑ Content length: {len(response.text)}")
        
        # T√¨m ki·∫øm JSON trong response
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # T√¨m script tags
        script_tags = soup.find_all('script')
        print(f"üîç T√¨m th·∫•y {len(script_tags)} script tags")
        
        # T√¨m __NEXT_DATA__
        next_data_script = soup.find('script', id='__NEXT_DATA__')
        if next_data_script:
            print("‚úÖ T√¨m th·∫•y __NEXT_DATA__ script!")
            try:
                json_data = json.loads(next_data_script.string)
                print(f"üîë Keys: {list(json_data.keys())}")
                return json_data
            except json.JSONDecodeError as e:
                print(f"‚ùå L·ªói parse JSON: {e}")
        else:
            print("‚ùå Kh√¥ng t√¨m th·∫•y __NEXT_DATA__ script")
        
        # T√¨m ki·∫øm c√°c script kh√°c
        for i, script in enumerate(script_tags):
            if script.string and script.string.strip():
                script_content = script.string.strip()
                if script_content.startswith('{') and script_content.endswith('}'):
                    try:
                        json_obj = json.loads(script_content)
                        print(f"‚úÖ T√¨m th·∫•y JSON trong script {i+1}")
                        print(f"üîë Keys: {list(json_obj.keys())}")
                        return json_obj
                    except json.JSONDecodeError:
                        continue
        
        return None
        
    except ImportError:
        print("‚ùå C·∫ßn c√†i ƒë·∫∑t requests: pip install requests")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói khi crawl: {e}")
        return None

def crawl_with_selenium():
    """
    Crawl b·∫±ng Selenium (n·∫øu c√≥)
    """
    print("üöÄ Th·ª≠ crawl b·∫±ng Selenium...")
    
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        
        # Setup Chrome options
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # Kh·ªüi t·∫°o driver
        driver = webdriver.Chrome(options=chrome_options)
        
        try:
            # Load trang web
            url = "https://www.willhaben.at/iad/gebrauchtwagen/auto/gebrauchtwagenboerse"
            print(f"üåê Loading: {url}")
            driver.get(url)
            
            # ƒê·ª£i trang load
            print("‚è≥ ƒê·ª£i trang load...")
            time.sleep(5)
            
            # T√¨m ki·∫øm d·ªØ li·ªáu JSON
            page_source = driver.page_source
            print(f"üìÑ Page source length: {len(page_source)}")
            
            # Parse HTML
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # T√¨m __NEXT_DATA__
            next_data_script = soup.find('script', id='__NEXT_DATA__')
            if next_data_script:
                print("‚úÖ T√¨m th·∫•y __NEXT_DATA__ script!")
                try:
                    json_data = json.loads(next_data_script.string)
                    print(f"üîë Keys: {list(json_data.keys())}")
                    return json_data
                except json.JSONDecodeError as e:
                    print(f"‚ùå L·ªói parse JSON: {e}")
            else:
                print("‚ùå Kh√¥ng t√¨m th·∫•y __NEXT_DATA__ script")
            
            # T√¨m ki·∫øm c√°c script kh√°c
            script_tags = soup.find_all('script')
            print(f"üîç T√¨m th·∫•y {len(script_tags)} script tags")
            
            for i, script in enumerate(script_tags):
                if script.string and script.string.strip():
                    script_content = script.string.strip()
                    if script_content.startswith('{') and script_content.endswith('}'):
                        try:
                            json_obj = json.loads(script_content)
                            print(f"‚úÖ T√¨m th·∫•y JSON trong script {i+1}")
                            print(f"üîë Keys: {list(json_obj.keys())}")
                            return json_obj
                        except json.JSONDecodeError:
                            continue
            
            return None
            
        finally:
            driver.quit()
            
    except ImportError:
        print("‚ùå C·∫ßn c√†i ƒë·∫∑t Selenium: pip install selenium")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói khi crawl v·ªõi Selenium: {e}")
        return None

def extract_car_data(json_data):
    """
    Tr√≠ch xu·∫•t d·ªØ li·ªáu xe t·ª´ JSON
    """
    print("üîç Tr√≠ch xu·∫•t d·ªØ li·ªáu xe t·ª´ JSON...")
    
    def search_recursive(obj, path=""):
        """T√¨m ki·∫øm ƒë·ªá quy"""
        results = []
        
        if isinstance(obj, dict):
            for key, value in obj.items():
                current_path = f"{path}.{key}" if path else key
                
                # T√¨m c√°c key c√≥ th·ªÉ ch·ª©a d·ªØ li·ªáu xe
                if key.lower() in ['adverts', 'ads', 'listings', 'results', 'items', 'advert']:
                    if isinstance(value, list):
                        print(f"üéØ T√¨m th·∫•y danh s√°ch t·∫°i: {current_path} ({len(value)} items)")
                        results.extend(value)
                    elif isinstance(value, dict):
                        print(f"üéØ T√¨m th·∫•y object t·∫°i: {current_path}")
                        results.append(value)
                
                # Ti·∫øp t·ª•c t√¨m ki·∫øm
                results.extend(search_recursive(value, current_path))
                
        elif isinstance(obj, list):
            for i, item in enumerate(obj):
                results.extend(search_recursive(item, f"{path}[{i}]"))
        
        return results
    
    car_data = search_recursive(json_data)
    print(f"üìä T√¨m th·∫•y {len(car_data)} potential car data items")
    
    return car_data

def parse_car_info(item):
    """
    Parse th√¥ng tin xe t·ª´ m·ªôt item
    """
    car_info = {}
    
    if isinstance(item, dict):
        # C√°c tr∆∞·ªùng c√≥ th·ªÉ c√≥
        fields_to_extract = [
            'id', 'adId', 'advertId', 'adId',
            'title', 'name', 'headline', 'subject',
            'price', 'priceAmount', 'priceValue',
            'url', 'selfLink', 'link', 'href',
            'description', 'text', 'content',
            'location', 'city', 'region', 'address',
            'year', 'yearOfConstruction', 'constructionYear',
            'mileage', 'km', 'kilometers',
            'fuel', 'fuelType', 'engine',
            'power', 'hp', 'horsepower',
            'transmission', 'gear', 'gearbox',
            'color', 'paint',
            'brand', 'make', 'manufacturer',
            'model', 'type',
            'images', 'pictures', 'photos',
            'dealer', 'seller', 'contact',
            'date', 'created', 'published',
            'condition', 'state'
        ]
        
        for field in fields_to_extract:
            if field in item:
                car_info[field] = item[field]
    
    return car_info

def main():
    print("üöÄ Crawl d·ªØ li·ªáu xe t·ª´ willhaben.at")
    
    # Th·ª≠ crawl b·∫±ng requests tr∆∞·ªõc
    json_data = crawl_with_requests()
    
    # N·∫øu kh√¥ng th√†nh c√¥ng, th·ª≠ Selenium
    if not json_data:
        print("\nüîÑ Th·ª≠ Selenium...")
        json_data = crawl_with_selenium()
    
    if not json_data:
        print("‚ùå Kh√¥ng th·ªÉ crawl d·ªØ li·ªáu")
        sys.exit(1)
    
    # Tr√≠ch xu·∫•t d·ªØ li·ªáu xe
    car_data = extract_car_data(json_data)
    
    if not car_data:
        print("‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu xe")
        sys.exit(1)
    
    # Parse th√¥ng tin xe
    parsed_cars = []
    for i, item in enumerate(car_data[:10]):  # Ch·ªâ l·∫•y 10 ƒë·∫ßu ti√™n
        print(f"\nüöó Parsing item {i+1}...")
        car_info = parse_car_info(item)
        parsed_cars.append(car_info)
        
        # In th√¥ng tin c∆° b·∫£n
        print(f"   ID: {car_info.get('id', 'N/A')}")
        print(f"   Title: {car_info.get('title', 'N/A')}")
        print(f"   Price: {car_info.get('price', 'N/A')}")
        print(f"   URL: {car_info.get('url', 'N/A')}")
    
    # L∆∞u k·∫øt qu·∫£
    output_file = "willhaben_cars_crawled.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(parsed_cars, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ ƒê√£ l∆∞u {len(parsed_cars)} xe v√†o file: {output_file}")
    
    # In t·ªïng k·∫øt
    print(f"\nüìä T·ªïng k·∫øt:")
    print(f"   - T·ªïng s·ªë items: {len(car_data)}")
    print(f"   - ƒê√£ parse: {len(parsed_cars)}")
    print(f"   - File output: {output_file}")

if __name__ == "__main__":
    main()
