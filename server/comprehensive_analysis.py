#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script tá»•ng há»£p Ä‘á»ƒ tÃ¬m táº¥t cáº£ cÃ¡c pattern cÃ³ thá»ƒ cÃ³ trong HTML
"""

import json
import re
import sys
from pathlib import Path
from bs4 import BeautifulSoup

def comprehensive_html_analysis(file_path):
    """
    PhÃ¢n tÃ­ch toÃ n diá»‡n HTML Ä‘á»ƒ tÃ¬m má»i pattern cÃ³ thá»ƒ cÃ³
    """
    print(f"ğŸš€ PhÃ¢n tÃ­ch toÃ n diá»‡n HTML tá»« file: {file_path}")
    
    try:
        # Äá»c file RTF
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        print(f"âœ… ÄÃ£ Ä‘á»c file: {len(content)} kÃ½ tá»±")
        
        # TÃ¬m HTML content trong RTF
        html_match = re.search(r'\\f0\\fs28\s*(.*?)(?=\\f0|$)', content, re.DOTALL)
        
        if not html_match:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y HTML content trong RTF")
            return None
            
        html_content = html_match.group(1)
        print(f"ğŸ“„ HTML content: {len(html_content)} kÃ½ tá»±")
        
        # Parse HTML vá»›i BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # 1. PhÃ¢n tÃ­ch meta tags
        print(f"\nğŸ“Š PhÃ¢n tÃ­ch Meta Tags:")
        meta_tags = soup.find_all('meta')
        for meta in meta_tags:
            if meta.get('name') == 'description':
                print(f"   - Description: {meta.get('content', 'N/A')}")
            elif meta.get('property') == 'og:title':
                print(f"   - OG Title: {meta.get('content', 'N/A')}")
            elif meta.get('property') == 'og:description':
                print(f"   - OG Description: {meta.get('content', 'N/A')}")
        
        # 2. TÃ¬m kiáº¿m táº¥t cáº£ text chá»©a tá»« khÃ³a liÃªn quan
        print(f"\nğŸ” TÃ¬m kiáº¿m tá»« khÃ³a liÃªn quan:")
        keywords = ['BMW', 'Audi', 'Mercedes', 'Volkswagen', 'Opel', 'Ford', 'â‚¬', 'km', 'Jahr', 'Gebrauchtwagen']
        for keyword in keywords:
            count = html_content.count(keyword)
            if count > 0:
                print(f"   - '{keyword}': {count} láº§n xuáº¥t hiá»‡n")
        
        # 3. TÃ¬m kiáº¿m cÃ¡c pattern sá»‘ (cÃ³ thá»ƒ lÃ  giÃ¡, nÄƒm, km)
        print(f"\nğŸ’° TÃ¬m kiáº¿m pattern sá»‘:")
        price_patterns = [
            r'â‚¬\s*\d+[.,]\d+',
            r'â‚¬\s*\d+',
            r'\d+[.,]\d+\s*â‚¬',
            r'\d+\s*â‚¬'
        ]
        
        for pattern in price_patterns:
            matches = re.findall(pattern, html_content)
            if matches:
                print(f"   - Pattern '{pattern}': {len(matches)} matches")
                print(f"     VÃ­ dá»¥: {matches[:5]}")
        
        # 4. TÃ¬m kiáº¿m nÄƒm (cÃ³ thá»ƒ lÃ  nÄƒm sáº£n xuáº¥t)
        year_pattern = r'\b(19|20)\d{2}\b'
        years = re.findall(year_pattern, html_content)
        if years:
            print(f"   - NÄƒm: {len(years)} matches - {set(years)}")
        
        # 5. TÃ¬m kiáº¿m km
        km_pattern = r'\b\d+[.,]\d+\s*km\b'
        km_matches = re.findall(km_pattern, html_content)
        if km_matches:
            print(f"   - KM: {len(km_matches)} matches - {km_matches[:5]}")
        
        # 6. TÃ¬m kiáº¿m cÃ¡c script tags vÃ  ná»™i dung
        print(f"\nğŸ“œ PhÃ¢n tÃ­ch Script Tags:")
        script_tags = soup.find_all('script')
        for i, script in enumerate(script_tags):
            if script.string:
                script_content = script.string.strip()
                print(f"   Script {i+1}: {len(script_content)} kÃ½ tá»±")
                print(f"     Báº¯t Ä‘áº§u: {script_content[:100]}...")
                
                # TÃ¬m kiáº¿m cÃ¡c pattern trong script
                if 'advert' in script_content.lower():
                    print(f"     âœ… Chá»©a tá»« 'advert'")
                if 'car' in script_content.lower():
                    print(f"     âœ… Chá»©a tá»« 'car'")
                if 'price' in script_content.lower():
                    print(f"     âœ… Chá»©a tá»« 'price'")
        
        # 7. TÃ¬m kiáº¿m cÃ¡c elements cÃ³ thá»ƒ chá»©a dá»¯ liá»‡u
        print(f"\nğŸ” TÃ¬m kiáº¿m Elements:")
        
        # TÃ¬m táº¥t cáº£ divs
        all_divs = soup.find_all('div')
        print(f"   - Tá»•ng sá»‘ divs: {len(all_divs)}")
        
        # TÃ¬m divs cÃ³ class
        divs_with_class = [div for div in all_divs if div.get('class')]
        print(f"   - Divs cÃ³ class: {len(divs_with_class)}")
        
        # TÃ¬m divs cÃ³ id
        divs_with_id = [div for div in all_divs if div.get('id')]
        print(f"   - Divs cÃ³ id: {len(divs_with_id)}")
        
        # TÃ¬m divs cÃ³ data attributes
        divs_with_data = [div for div in all_divs if any(attr.startswith('data-') for attr in div.attrs)]
        print(f"   - Divs cÃ³ data attributes: {len(divs_with_data)}")
        
        # 8. TÃ¬m kiáº¿m cÃ¡c pattern JSON trong toÃ n bá»™ HTML
        print(f"\nğŸ” TÃ¬m kiáº¿m JSON Patterns:")
        
        # TÃ¬m táº¥t cáº£ cÃ¡c object JSON cÃ³ thá»ƒ cÃ³
        json_patterns = [
            r'\{[^{}]*"advert"[^{}]*\}',
            r'\{[^{}]*"ad"[^{}]*\}',
            r'\{[^{}]*"car"[^{}]*\}',
            r'\{[^{}]*"auto"[^{}]*\}',
            r'\{[^{}]*"vehicle"[^{}]*\}',
            r'\{[^{}]*"price"[^{}]*\}',
            r'\{[^{}]*"title"[^{}]*\}',
            r'\{[^{}]*"description"[^{}]*\}',
        ]
        
        for pattern in json_patterns:
            matches = re.findall(pattern, html_content, re.IGNORECASE)
            if matches:
                print(f"   - Pattern '{pattern}': {len(matches)} matches")
                for match in matches[:3]:
                    print(f"     VÃ­ dá»¥: {match[:100]}...")
        
        # 9. TÃ¬m kiáº¿m cÃ¡c pattern khÃ¡c
        print(f"\nğŸ” TÃ¬m kiáº¿m cÃ¡c Pattern khÃ¡c:")
        
        # TÃ¬m cÃ¡c pattern cÃ³ thá»ƒ chá»©a dá»¯ liá»‡u
        other_patterns = [
            r'data-[a-zA-Z-]+="[^"]*"',
            r'id="[^"]*"',
            r'class="[^"]*"',
            r'href="[^"]*"',
            r'src="[^"]*"',
        ]
        
        for pattern in other_patterns:
            matches = re.findall(pattern, html_content)
            if matches:
                print(f"   - Pattern '{pattern}': {len(matches)} matches")
                print(f"     VÃ­ dá»¥: {matches[:3]}")
        
        return {
            'html_content': html_content,
            'soup': soup,
            'analysis': {
                'total_chars': len(html_content),
                'script_tags': len(script_tags),
                'divs': len(all_divs),
                'keywords_found': {kw: html_content.count(kw) for kw in keywords if html_content.count(kw) > 0}
            }
        }
        
    except Exception as e:
        print(f"âŒ Lá»—i khi phÃ¢n tÃ­ch HTML: {e}")
        return None

def suggest_solutions(analysis_result):
    """
    ÄÆ°a ra cÃ¡c giáº£i phÃ¡p dá»±a trÃªn káº¿t quáº£ phÃ¢n tÃ­ch
    """
    print(f"\nğŸ’¡ Äá» xuáº¥t giáº£i phÃ¡p:")
    
    if not analysis_result:
        print("âŒ KhÃ´ng thá»ƒ phÃ¢n tÃ­ch file")
        return
    
    analysis = analysis_result['analysis']
    
    print(f"ğŸ“Š Káº¿t quáº£ phÃ¢n tÃ­ch:")
    print(f"   - File chá»©a HTML tÄ©nh tá»« Next.js")
    print(f"   - CÃ³ {analysis['script_tags']} script tags (external)")
    print(f"   - CÃ³ {analysis['divs']} div elements")
    print(f"   - Tá»« khÃ³a tÃ¬m tháº¥y: {analysis['keywords_found']}")
    
    print(f"\nğŸ¯ Káº¿t luáº­n:")
    print(f"   - File RTF nÃ y chá»©a HTML Ä‘Æ°á»£c render tá»« Next.js")
    print(f"   - Dá»¯ liá»‡u xe KHÃ”NG cÃ³ trong HTML tÄ©nh")
    print(f"   - Dá»¯ liá»‡u Ä‘Æ°á»£c load Ä‘á»™ng báº±ng JavaScript")
    
    print(f"\nğŸš€ Giáº£i phÃ¡p Ä‘á» xuáº¥t:")
    print(f"   1. Sá»­ dá»¥ng Selenium/Playwright Ä‘á»ƒ render trang web")
    print(f"   2. Sá»­ dá»¥ng API cá»§a willhaben.at (náº¿u cÃ³)")
    print(f"   3. Sá»­ dá»¥ng headless browser Ä‘á»ƒ crawl dá»¯ liá»‡u")
    print(f"   4. PhÃ¢n tÃ­ch network requests Ä‘á»ƒ tÃ¬m API endpoints")
    
    print(f"\nğŸ“ Script máº«u vá»›i Selenium:")
    print(f"""
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import time
import json

# Setup Chrome driver
chrome_options = Options()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(options=chrome_options)

try:
    # Load trang web
    driver.get('https://www.willhaben.at/iad/gebrauchtwagen/auto/gebrauchtwagenboerse')
    
    # Äá»£i trang load
    time.sleep(5)
    
    # TÃ¬m dá»¯ liá»‡u JSON trong page source
    page_source = driver.page_source
    
    # TÃ¬m __NEXT_DATA__ hoáº·c cÃ¡c script chá»©a dá»¯ liá»‡u
    # ... (code Ä‘á»ƒ parse dá»¯ liá»‡u)
    
finally:
    driver.quit()
""")

def main():
    if len(sys.argv) != 2:
        print("Usage: python comprehensive_analysis.py <path_to_rtf_file>")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    if not Path(file_path).exists():
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {file_path}")
        sys.exit(1)
    
    # PhÃ¢n tÃ­ch toÃ n diá»‡n
    analysis_result = comprehensive_html_analysis(file_path)
    
    # ÄÆ°a ra giáº£i phÃ¡p
    suggest_solutions(analysis_result)
    
    # LÆ°u káº¿t quáº£
    if analysis_result:
        output_file = "comprehensive_analysis.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_result['analysis'], f, ensure_ascii=False, indent=2)
        print(f"\nâœ… ÄÃ£ lÆ°u káº¿t quáº£ phÃ¢n tÃ­ch vÃ o file: {output_file}")

if __name__ == "__main__":
    main()
